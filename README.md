# Sign-Language-Translation-to-Text-and-Speech
The Sign Language Conversion project presents a real-time system that can interpret sign language from a live webcam feed. 
Leveraging the power of the Mediapipe library for landmark detection, the project extracts vital information from each frame, including hand landmarks.
The detected landmark coordinates are then collected and stored in a CSV file for further analysis. 
Using machine learning techniques, a Random Forest Classifier is trained on this landmark data to classify different sign language patterns. 
This project showcases the fusion of computer vision and machine learning methodologies to interpret and understand non-verbal communication, with potential applications in human-computer interaction.
